def add_index_to_df(df, index_col_name="index"):
    df_with_index = df.rdd.zipWithIndex()
    df_with_index = df_with_index.map(lambda row: Row(**{index_col_name: row[1], **row[0].asDict()})).toDF()
    df_with_index = df_with_index.withColumn(index_col_name, col(index_col_name).cast("int"))
    return df_with_index

For more details, please visit
https://github.com/mohan1998g/PySpark/blob/a4d009920d8379aae1667429add6c1c986cdc1e5/zipWithIndex%20function%20in%20pyspark#L273
